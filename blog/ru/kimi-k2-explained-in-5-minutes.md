# Kimi K2 объясняется за 5 минут

Недавно я посмотрел видео и нашел его довольно познавательным. Чтобы лучше понять и поделиться содержанием, я использовал **[Viddo](https://viddo.pro/)** для преобразования видео в структурированную статью, которая послужила основой для этого анализа.

**Оригинальное видео:** [Смотреть видео](> - Kimike K2 от Moonshot вызывает бурю в индустрии ИИ. 
> - Многие по-прежнему предпочитают модели, такие как Claude и Gemini. 
> - Потенциал Kimike K2 заключается в его инновационной архитектуре. 
> - Финансовые факторы влияют на принятие Kimike K2. 
> - Эволюция моделей с открытым исходным кодом может изменить конкурентный ландшафт.

Kimike K2 был выпущен Moonshot и оказывает большое влияние на индустрию ИИ. И вы можете сказать: нет, я использую Claude и Gemini, и они работают вполне нормально, поэтому почему мне действительно стоит беспокоиться об этом?

Большинство людей, вероятно, никогда не слышали о Kimik K2 или даже о Moonshot, потому что на коммерческой стороне рынок в основном контролируется OpenAI, Anthropic и Gemini. Но есть причина, по которой сообщество открытых моделей восхищается такими моделями, как Kimikk 2.

Причина, по которой Kimikk 2 не так широко известен, в основном связана со словом **большой** в большом языковом модели, что означает, что эти модели с открытым исходным кодом все еще слишком велики для локального запуска, чтобы достичь таких же результатов, как современные образцовые модели.

Например, Kimi K2 имеет в общей сложности **1 триллион параметров**, что сравнимо с другими передовыми моделями, такими как GPT, Gemini и Claude. **Конкурентное преимущество**, которое имеют эти модели над Kimikk 2, заключается в **экономии на масштабе**. Я имею в виду, что для запуска модели с триллионом параметров для миллионов пользователей, которых у них есть, вам необходима **инфраструктура крупного масштаба** для ее поддержки.

К сожалению, для запуска Kimmikk 2 вам нужно потратить около **$25,000** минимум на покупку карты Nvidia H100, что похоже на покупку нового автомобиля. И, как и в случае с автомобилем, вам нужно заправлять его бензином для работы. Использование H100 может стоить до **$90 в месяц** для локального запуска, потребляя около **0.7 киловатт**.

Итак, вы можете спросить, в чем действительно дело здесь? Похоже, Kimikk 2 все еще не совсем готов, верно? Конечно, математические расчеты все еще favor коммерчески доступные модели, потому что вы платите только абонентскую плату в размере **$200 в месяц** за разработчика для **неограниченных API вызовов**, чтобы использовать современные образцовые модели, такие как Claude. Это всего лишь **$2,400 в год**, что значительно меньше, чем уплатить **$25,000** за запуск Kimik K2.

Но если рассматривать это с точки зрения компании, то платить **$2,400 в год** за разработчика, математика начинает постепенно наклоняться в другую сторону. Например, **$25,000 аппаратного обеспечения**, которое компания приобрела, можно рассматривать как первоначальные инвестиции, которые вы платите сразу как капитальные расходы и которые можно амортизировать в налогах.

И вдобавок к этому, в следующем году затраты на электричество для вывода составят всего **$1,080 в год**, что намного меньше, чем **$2,400**, и потенциально еще меньше, если такое же оборудование будет разделено между двух разработчиков.

Таким образом, вы можете понять, почему вокруг таких моделей, как Kimmik K2, так много волнений, поскольку рынок открытых моделей медленно настигает момент, когда **сравнимые с современными образцовыми моделями** модели, такие как Kimmik K2, теперь могут использоваться локально. Поэтому очевидный следующий вопрос — **как?**

Как Kimik K2 удается так хорошо конкурировать с образцовыми моделями, такими как Claude GPT и Gemini? Архитектура Kimikk 2 построена на так называемом **MOE** или **смеси экспертов**. Большинство коммерческих моделей, таких как GPT и Claude, являются так называемыми **плотными моделями**, в то время как Kimikk 2 является **разреженной моделью**.

Плотная модель — это типичная нейронная сеть с прямой связью, которая может активировать всю модель для обработки токенов, в то время как разреженные модели активируют только раздел или несколько разделов модели для обработки ваших токенов. Именно поэтому, хотя Kimi K2 имеет **1 триллион параметров** в размере, он на самом деле активирует только **8 разделов**, в данном случае 8 экспертов на токен.

Модель имеет в общей сложности **384 эксперта**, которые все составляют около **1 триллиона параметров** в размере, и это делает вывод гораздо быстрее с учетом размера, поскольку она использует только **32 миллиарда активных параметров** за раз.

Kimik 2 также построен вокруг действий, что означает, что он специально обучен для более эффективных вызовов инструментов. И я думаю, что это очень важный момент, где **показатели LLM**, которые обычно используются для измерения сырой интеллекта данной модели, теперь расширяются, чтобы искать модели, которые более **ресурсные**, способные использовать внешние сервисы и инструменты для выполнения более эффективных действий.

Moonshot осознает и специально обучила Kimik K2 для **использования инструментов SIM**, чтобы научиться быть ресурсным в правильных вызовах инструментов для **разных целей** и **разных контекстов**. И это принесет огромные дивиденды, поскольку индустрия сдвигается в сторону **MCP** и **A2A** или **сети Агент к Агенту**, которые требуют большого количества внешней зависимости.

Мой следующий вопрос тогда - как Kimik 2 совмещается с тем, что произошло в **январе 2025 года**, когда был впервые выпущен DeepSeek 1 и потряс мир? Помните, когда объявление о Deepsea появилось как **убийца Chat GPT** и фондовый рынок в итоге упал на триллион долларов?

В конечном итоге, будут ли затраты на эксплуатацию этих моделей сопоставимы с использованием передовых моделей, таких как **GPT от OpenAI**, **Claude от Anthropic** и **Gemini от Google?** Для каждого значимого выпуска, такого как Deepseek1 или Kimik K2, это начинает устранять конкурентные преимущества, которыми в настоящее время обладают эти компании.

И я думаю, что именно поэтому поставщики LLM понимают, что их конкурентные преимущества не являются постоянными, и именно поэтому мы видим, что они расширяют свои предложения продуктов на смежные продукты, такие как **AI редакторы кода**, **AI веб-браузеры** и **AI чат-приложения**, и многое другое, потому что это позволяет им поддерживать свое конкурентное преимущество немного дольше.

Поэтому, когда мы ожидаем, что модели с открытым исходным кодом, такие как Kimik K2, будут становиться более доступными и полезными, мы увидим, как **индустрия изменяется**. И будет интересно увидеть, где **самостоятельный хостинг** начнет становиться нормой. Или, возможно, коммерческие модели продолжат доминировать в индустрии, потому что они могут просто вложить больше **денег** в более быструю инновацию.  
**Справочная статья:** [Смотреть на Viddo](https://viddo.pro/zh/video-result/72068e82-62a8-4ef9-b6f8-09eaae0e0b0a)

---

Недавно я наткнулся на видео, в котором обсуждается модель Kimike K2 от Moonshot. После просмотра я был впечатлен, тем более что это может оказать тонкое, но сильное влияние на всю экосистему моделей AI.

---

**⚡️Вдохновение, стоящее за Kimike K2, четкое и смелое:** хотя он не так известен, как GPT или Claude, он демонстрирует возможность открытого сообщества постепенно догнать коммерческих гигантов, даже в некоторых архитектурных дизайнах быть более радикальным. Это не просто соревнование технологий, это игра на тему "кто в будущем будет обладать суверенитетом AI".

---

> **"Один триллион параметров не для похвал, а для равновесия между точностью и эффективностью."**  
> **"Архитектура MOE позволяет K2 активировать меньше параметров, но работать быстрее."**  
> **"Обладать моделью - это как иметь машину, а не просто покупать билет на поезд."**

---

Честно говоря, я изначально не придавал большого значения этим менее популярным моделям, потому что Claude и GPT уже удовлетворяли большинство моих потребностей. Но это видео заставило меня переосмыслить вопрос "владения": удобно ли арендовать сервис или собственная система дает больше свободы?

Kimike K2 достигает облегченной работы на триллионном уровне параметров с помощью архитектуры Mixture of Experts, хотя порог аппаратных требований все еще высок (H100 стоимостью в десятки тысяч долларов), но если посчитать с точки зрения компании, он не обязательно будет дороже подписки на коммерческие API. Более того, сама модель обучается быть более "умелой" — она не только умная, но и знает, как использовать инструменты для выполнения задач.

Это именно то, что меня больше всего впечатляет: **будущее AI — это не только общение и написание, но также больше похоже на "работоспособного" цифрового помощника.** Moonshot сосредоточился на вопросе "как заставить AI действительно работать", и этот подход мне очень близок.

Подумав об этом, я внезапно осознал: возможно, мы не просто смотрим на "еще одну открытую модель", а являемся свидетелями настоящего пересечения открытого и коммерческого путей. Возможно, через год или два мы действительно сможем обладать "суверенитетом" AI. И это действительно самая захватывающая перспектива будущего.

---

**Хотите преобразовать свои собственные видео в статьи?** Попробуйте **[Viddo](https://viddo.pro/)** - платформу на основе ИИ, которая преобразует видео-содержимое в привлекательные и читаемые статьи за считанные минуты. Идеально подходит для создателей контента, педагогов и профессионалов, которые хотят переработать свое видео-содержимое для блогов, социальных медиа или документации.

[🚀 Начните преобразование видео с Viddo](https://viddo.pro/)