# Kimi K2 expliquÃ© en 5 minutes

J'ai rÃ©cemment regardÃ© une vidÃ©o et je l'ai trouvÃ©e trÃ¨s instructive. Pour mieux comprendre et partager le contenu, j'ai utilisÃ© **[Viddo](https://viddo.pro/)** pour convertir la vidÃ©o en un article structurÃ©, qui a servi de rÃ©fÃ©rence pour cette analyse.

**VidÃ©o originale :** [Regarder la vidÃ©o](> - Kimike K2 de Moonshot fait des vagues dans l'industrie de l'IA.
> - Beaucoup prÃ©fÃ¨rent encore des modÃ¨les comme Claude et Gemini.
> - Le potentiel de Kimike K2 rÃ©side dans son architecture innovante.
> - Les facteurs de coÃ»t influencent l'adoption de Kimike K2.
> - L'Ã©volution des modÃ¨les open source pourrait changer le paysage concurrentiel.

Kimike K2 a Ã©tÃ© lancÃ© par Moonshot et cela a un grand impact dans l'industrie de l'IA. Et vous pourriez dire non, j'utilise Claude et Gemini, et ils fonctionnent trÃ¨s bien, alors pourquoi devrais-je vraiment me soucier de cela ?

La plupart des gens n'ont probablement jamais entendu parler de Kimik K2 ou mÃªme de Moonshot, car du cÃ´tÃ© commercial, le marchÃ© est largement dominÃ© par OpenAI, Anthropic et Gemini. Mais il y a une raison pour laquelle la communautÃ© des modÃ¨les open source parle en bien de modÃ¨les comme Kimikk 2.

La raison pour laquelle Kimikk 2 n'est pas largement connu est principalement liÃ©e au mot **large** dans le modÃ¨le de langage large, ce qui signifie que ces modÃ¨les open source sont encore trop grands pour Ãªtre exÃ©cutÃ©s localement afin d'obtenir le mÃªme rÃ©sultat que les modÃ¨les les plus avancÃ©s.

Par exemple, Kimi K2 a un total de **1 trillion de paramÃ¨tres**, ce qui est comparable Ã  d'autres modÃ¨les de pointe comme GPT, Gemini et Claude. L'**avantage concurrentiel** que ces modÃ¨les ont sur Kimikk 2 est les **Ã©conomies d'Ã©chelle**. Ce que je veux dire par lÃ , c'est que pour faire fonctionner un modÃ¨le de 1 trillion de paramÃ¨tres pour des millions d'utilisateurs qu'ils ont, il faut une **infrastructure Ã  grande Ã©chelle** pour le soutenir.

Et malheureusement, pour faire fonctionner Kimmikk 2, vous devez dÃ©penser environ **25 000 $** au minimum pour acheter la carte Nvidia H100, ce qui est similaire Ã  l'achat d'une voiture neuve. Et tout comme possÃ©der une voiture, vous devez mettre de l'essence pour la faire fonctionner. Et H100 peut coÃ»ter jusqu'Ã  **90 $ par mois** pour Ãªtre exÃ©cutÃ© localement, en dÃ©pensant environ **0,7 kilowatts**.

Alors vous pourriez vous demander Ã  ce stade quel est vraiment le gros problÃ¨me ici ? Il semble donc que Kimikk 2 ne soit pas vraiment Ã  la hauteur, n'est-ce pas ? Certes, les chiffres favorisent encore les modÃ¨les commerciaux car vous ne payez qu'un frais d'abonnement de **200 $ par mois** par dÃ©veloppeur pour avoir **des appels API illimitÃ©s** pour utiliser des modÃ¨les Ã  la pointe de la technologie comme Claude. C'est seulement **2 400 $ par an**, ce qui est significativement moins que de dÃ©penser **25 000 $** pour faire fonctionner Kimik K2.

Si vous y rÃ©flÃ©chissez du point de vue d'une entreprise, cependant, payer **2 400 $ par an** par dÃ©veloppeur, les chiffres commencent lentement Ã  s'orienter dans l'autre sens. Par exemple, le **matÃ©riel de 25 000 $** qu'une entreprise a achetÃ© pourrait Ãªtre considÃ©rÃ© comme un investissement initial que vous payez d'avance en tant que dÃ©pense en capital et qui peut Ãªtre amortie dans les impÃ´ts.

Et en plus de cela, l'annÃ©e suivante, cela ne coÃ»tera que **1 080 $ par an** en frais d'Ã©lectricitÃ© pour l'infÃ©rence, ce qui est bien moins que les **2 400 $** et potentiellement moins si le mÃªme Ã©quipement est partagÃ© entre deux dÃ©veloppeurs.

Donc, vous pouvez voir pourquoi il y a tellement d'enthousiasme autour de ces modÃ¨les comme Kimmik K2, car le marchÃ© des modÃ¨les open source rattrape lentement un point oÃ¹ des **modÃ¨les comparables Ã  la pointe** comme Kimmik K2 peuvent maintenant Ãªtre utilisÃ©s localement. Alors la question Ã©vidente suivante est **comment ?**

Comment est-ce que Kimik K2 rÃ©ussit Ã  bien se positionner face Ã  des modÃ¨les de pointe comme Claude GPT et Gemini ? L'architecture de Kimikk 2 est construite autour de ce qu'on appelle **MOE** ou **mÃ©lange d'experts**. La plupart des modÃ¨les commerciaux comme GPT et Claude sont ce qu'on appelle des **modÃ¨les denses**, tandis que Kimikk 2 est un **modÃ¨le sparse**.

Un modÃ¨le dense est votre rÃ©seau de neurones classique alimentÃ© en avant qui peut activer l'ensemble du modÃ¨le pour traiter des tokens, tandis que les modÃ¨les sparse n'activent qu'une section ou quelques sections du modÃ¨le pour traiter vos tokens. C'est pourquoi, mÃªme si Kimi K2 possÃ¨de **1 trillion de paramÃ¨tres**, il active en fait seulement **8 sections**, dans ce cas, 8 experts par token.

Le modÃ¨le a un total de **384 experts** qui totalisent environ **1 trillion de paramÃ¨tres** en taille, et cela rend l'infÃ©rence beaucoup plus rapide compte tenu de sa taille, car il n'utilise que **32 milliards de paramÃ¨tres actifs** Ã  la fois.

Kimik 2 est Ã©galement construit autour d'actions, ce qui signifie qu'il est spÃ©cifiquement formÃ© pour effectuer de meilleurs appels d'outils. Et je pense que c'est un point trÃ¨s important oÃ¹ les **benchmarks LLM**, qui sont typiquement utilisÃ©s pour mesurer l'intelligence brute d'un modÃ¨le donnÃ©, s'Ã©largissent maintenant pour chercher des modÃ¨les qui sont plus **ingÃ©nieux** en Ã©tant capables de tirer parti de services externes et d'outils pour crÃ©er de meilleures actions.

Moonshot reconnaÃ®t et a spÃ©cifiquement formÃ© Kimik K2 sur l'**utilisation des outils SIM** pour apprendre Ã  Ãªtre ingÃ©nieux dans l'appel des bons outils pour **diffÃ©rents objectifs** et **diffÃ©rents contextes**. Et cela rapportera un Ã©norme dividende alors que l'industrie Ã©volue vers des **MCP** et des **A2A** ou des **rÃ©seaux Agent Ã  Agent**, ce qui nÃ©cessite beaucoup de dÃ©pendance externe.

Ma prochaine question est donc : comment Kimik 2 se positionne par rapport Ã  ce qui s'est passÃ© en **janvier 2025** lorsque DeepSeek 1 a Ã©tÃ© lancÃ© en premier et a secouÃ© le monde ? Vous vous souvenez lorsque l'annonce de Deepsea est sortie comme **tueur de Chat GPT** et que le marchÃ© boursier a fini par chuter d'un trillion de dollars ?

Au final, le coÃ»t d'exploitation de ces modÃ¨les sera-t-il comparable Ã  celui de l'utilisation de modÃ¨les de pointe comme **GPT d'OpenAI**, **Claude d'Anthropic**, et **Gemini de Google ?** Pour chaque grande sortie comme Deepseek1 ou Kimik K2, cela commence Ã  Ã©liminer l'avantage concurrentiel que ces entreprises apprÃ©cient actuellement.

Et je pense que c'est pourquoi les fournisseurs LLM reconnaissent que leur avantage concurrentiel n'est pas permanent, c'est pourquoi nous les voyons Ã©tendre leur offre de produits Ã  des produits adjacents comme des **Ã©diteurs de code IA**, des **navigateurs web IA** et des **applications de chat IA**, et plus encore, car cela maintient leur avantage concurrentiel un peu plus longtemps.

Ainsi, alors que nous attendons avec impatience des modÃ¨les open source comme Kimik K2 devenant de plus en plus disponibles et utiles, nous verrons comment l'**industrie Ã©volue**. Et il sera intÃ©ressant de voir oÃ¹ **l'auto-hÃ©bergement** commencera Ã  devenir la norme. Ou peut-Ãªtre que les modÃ¨les commerciaux continueront Ã  dominer l'industrie parce qu'ils peuvent simplement investir plus de **dollars** pour une innovation plus rapide.)
**Article de rÃ©fÃ©rence :** [Voir sur Viddo](https://viddo.pro/zh/video-result/72068e82-62a8-4ef9-b6f8-09eaae0e0b0a)

---

RÃ©cemment, je suis tombÃ© sur une vidÃ©o qui parlait du modÃ¨le Kimike K2 lancÃ© par Moonshot, et aprÃ¨s l'avoir regardÃ©e, j'Ã©tais assez choquÃ©, surtout par l'impact subtil mais fort qu'il pourrait avoir sur l'ensemble de l'Ã©cosystÃ¨me des modÃ¨les d'IA.

---

**âš¡ï¸L'inspiration derriÃ¨re Kimike K2 est claire et audacieuse :** bien qu'il ne soit pas aussi connu que GPT ou Claude, il montre la possibilitÃ© pour la communautÃ© open source de rattraper les gÃ©ants commerciaux, et mÃªme d'Ãªtre plus audacieux sur certains aspects de son architecture. Ce n'est pas simplement une course technologique, mais aussi un jeu sur "qui aura la souverainetÃ© de l'IA dans le futur".

---

> **"Un trillion de paramÃ¨tres, ce n'est pas pour faire le show, mais pour un Ã©quilibre entre prÃ©cision et efficacitÃ©."**  
> **"L'architecture MOE permet Ã  K2 d'activer moins de paramÃ¨tres tout en Ã©tant plus rapide."**  
> **"PossÃ©der un modÃ¨le, c'est comme possÃ©der une voiture, et non pas seulement acheter un ticket de transport."**

---

HonnÃªtement, je ne me prÃ©occupais pas de ces modÃ¨les moins courants, car Claude et GPT satisfaisaient la plupart de mes besoins. Mais cette vidÃ©o m'a fait repenser Ã  la question de la "propriÃ©tÃ©" : est-il plus pratique de louer un service ou est-il plus libre de possÃ©der un systÃ¨me ?

Kimike K2 rÃ©alise un fonctionnement lÃ©ger Ã  une Ã©chelle de trillion de paramÃ¨tres grÃ¢ce Ã  son architecture Mixture of Experts, bien que le seuil matÃ©riel soit encore trÃ¨s Ã©levÃ© (des cartes H100 coÃ»tant facilement deux Ã  trois fois plus de 10 000 $), mais si l'on regarde cela du point de vue de l'entreprise, cela pourrait ne pas Ãªtre plus cher qu'un abonnement Ã  une API commerciale. Plus important encore, le modÃ¨le lui-mÃªme est formÃ© pour Ãªtre plus "pratique" - il est non seulement intelligent, mais il sait aussi comment utiliser des outils pour effectuer des tÃ¢ches.

C'est exactement ce que je trouve le plus frappant : **l'IA du futur ne se limite pas Ã  discuter et Ã  Ã©crire, mais devient davantage un "assistant numÃ©rique capable de travailler."** Moonshot a mis son accent sur "comment faire en sorte que l'IA fasse rÃ©ellement quelque chose", et cette approche me parle beaucoup.

Ã€ ce stade, je rÃ©alise soudain que peut-Ãªtre nous ne regardons pas simplement "un autre modÃ¨le open source", mais que nous assistons Ã  la vÃ©ritable convergence des voies open source et commerciale. Peut-Ãªtre qu'au bout d'un an ou deux, la "souverainetÃ©" de l'IA pourrait rÃ©ellement Ãªtre entre nos mains. C'est cela, le futur qui est le plus excitant.

---

**Vous voulez convertir vos propres vidÃ©os en articles ?** Essayez **[Viddo](https://viddo.pro/)** - la plateforme alimentÃ©e par l'IA qui transforme le contenu vidÃ©o en articles engageants et lisibles en quelques minutes. Parfait pour les crÃ©ateurs de contenu, les Ã©ducateurs et les professionnels qui souhaitent rÃ©utiliser leur contenu vidÃ©o pour des blogs, des rÃ©seaux sociaux ou des documentations.

[ğŸš€ Commencez Ã  convertir des vidÃ©os avec Viddo](https://viddo.pro/)