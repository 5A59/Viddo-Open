# Kimi K2 在 5 分钟内的解读

最近我看了一段视频，觉得非常有启发。为了更好地理解和分享内容，我使用了 **[Viddo](https://viddo.pro/)** 将视频转换为结构化文章，这为本文的分析提供了参考。

**原视频:** [观看视频](> - Kimike K2 由 Moonshot 推出，正在 AI 行业掀起波澜。
> - 许多人仍然偏好 Claude 和 Gemini 等模型。
> - Kimike K2 的潜力在于其创新的架构。
> - 成本因素正在影响 Kimike K2 的采用。
> - 开源模型的演变可能改变竞争格局。

Kimike K2 是由 Moonshot 推出的，它正在 AI 行业产生重大影响。你可能会说，不，我一直在使用 Claude 和 Gemini，它们运行得很好，那么我为什么要在乎这个呢？

大多数人可能从未听说过 Kimike K2 或者 Moonshot，因为在商业领域，市场主要由 OpenAI、Anthropic 和 Gemini 主导。但开源模型社区对 Kimike K2 等模型的热议是有原因的。

Kimike K2 不为人知的原因主要与“大规模”这个词有关，这意味着这些开源模型仍然太大，无法在本地运行以获得与最先进模型相同的结果。

例如，Kimi K2 的参数总数为 **1 万亿**，与其他前沿模型如 GPT、Gemini 和 Claude 相当。与 Kimike K2 相比，这些模型的**竞争优势**在于**规模经济**。我的意思是，要为他们拥有的数百万用户运行一个万亿参数的模型，就需要一个**大规模基础设施**来支持。

遗憾的是，要运行 Kimik K2，你需要至少花费**25,000 美元**购买 Nvidia 的 H100 模型，这和买一辆新车相似。就像拥有一辆车一样，你需要加油才能开动它。而 H100 本地运行每月可能高达 **90 美元**，耗电大约为 **0.7 千瓦**。

所以你可能会问，到底这里有什么大不了的？看起来 Kimikk 2 还没有达到成熟的程度，对吧？当然，数学上的确仍然偏向商业模型，因为你只需每位开发者每月支付 **200 美元** 的订阅费，就可以**无限次调用 API** 来使用像 Claude 这样的最先进模型。这一年花费仅为 **2,400 美元**，显著低于运行 Kimik K2 的 **25,000 美元**。

然而，如果从公司角度看，每位开发者每年支付 **2,400 美元**，数学上的计算开始慢慢倾斜向另一边。例如，公司的 **25,000 美元硬件** 可以视为一项初始投资，作为资本支出提前支付，可以在税务上进行折旧。

此外，第二年仅需支付 **1,080 美元的电费**用于推理，这远低于 **2,400 美元**，如果同一设备在两个开发者之间共享，成本可能会更低。

因此，你可以理解为何对 Kimik K2 等模型如此兴奋，因为开源模型市场正在慢慢赶上，达到**与最先进型号可比的模型**（如 Kimik K2）现在可以在本地使用的程度。那么显而易见的下一个问题是**如何？**

Kimik K2 是如何能在性能上与 Claude GPT 和 Gemini 等最先进模型相抗衡的呢？Kimikk 2 的架构基于所谓的**MOE**或**专家混合**。大多数商业模型如 GPT 和 Claude 是所谓的**密集模型**，而 Kimikk 2 是**稀疏模型**。

密集模型是典型的前馈神经网络，可以激活整个模型来处理标记，而稀疏模型仅激活模型的一部分或几部分来处理标记。这就是为什么尽管 Kimi K2 的规模为 **1 万亿参数**，但它实际上只激活 **8 个部分**，在这种情况下每个标记激活 8 个专家。

该模型共有 **384 个专家**，总共有约 **1 万亿参数**的规模，这使得推理速度大大加快，因为它每次仅利用 **320 亿个活跃参数**。

Kimik 2 还围绕动作构建，这意味着它特别训练以更好地进行工具调用。我认为这是一个非常重要的点，即**LLM 基准**，通常用于衡量给定模型的原始智能，现在正扩展到寻找更**灵活**的模型，以便能够利用外部服务和工具来创造更好的行动。

Moonshot 认识到并专门训练 Kimik K2 使用 **SIM 工具**，以学习如何在**不同目的**和**不同上下文**中灵活调用正确的工具。随着行业转向 **MCP** 和 **A2A** 或 **代理到代理网络**，这将带来巨大的红利，因为这需要大量外部依赖。

接下来的问题是 Kimik 2 和 **2025 年 1 月** DeepSeek 1 首次发布引起的轰动之间有什么关系？还记得当 Deepsea 发布时被称为**Chat GPT 杀手**时，股市一度下跌了一个万亿吗？

最终，运营这些模型的成本会不会与使用前沿模型如 **OpenAI 的 GPT**、**Anthropic 的 Claude** 和 **Google 的 Gemini** 相当？对于每一个像 Deepseek1 或 Kimik K2 的重要发布，它逐渐消除了这些公司目前享有的竞争优势。

我认为这正是 LLM 提供者认识到其竞争优势并非永久的原因，这也是我们看到他们扩大产品提供至相邻产品如 **AI 代码编辑器**、**AI 网页浏览器**、**AI 聊天应用**等的原因，这样可以让他们的竞争优势持续更久。

因此，当我们期待开源模型如 Kimik K2 变得更加可用和有用时，我们将看到**行业的变化**。很有趣的是，**自托管**将何时开始成为常态。或者，也许商业模型将继续主导行业，因为他们可以投入更多**资金**以加快创新。

**参考文章:** [在 Viddo 上查看](https://viddo.pro/zh/video-result/72068e82-62a8-4ef9-b6f8-09eaae0e0b0a)

---

最近我刷到一支视频，讲的是 Moonshot 推出的 Kimike K2 模型，看完之后我挺震撼的，尤其是它对整个 AI 模型生态可能带来的那种微妙但强烈的冲击。

---

**⚡️Kimike K2 背后的启发是清晰而大胆的：**虽然它不像 GPT、Claude 那样家喻户晓，但它展现了开源社区逐渐追上商业巨头的可能性，甚至在某些架构设计上更为激进。这不仅仅是一场技术竞赛，更是一种关于“未来谁拥有 AI 主权”的博弈。

---

> **“一万亿参数，不是为了炫技，而是为了精度与效率的平衡。”**  
> **“MOE 架构让 K2 激活更少参数，却跑得更快。”**  
> **“拥有模型，就像拥有一辆车，而不是只买车票。”**

---

老实说，我原本并没有太在意这些不那么主流的模型，因为 Claude 和 GPT 已经满足了我大多数需求。但这支视频让我开始重新思考“拥有权”这件事：是租一个服务方便，还是自己拥有一套系统更自由？

Kimike K2 通过 Mixture of Experts 架构实现了在万亿参数下的轻量化运行，虽然硬件门槛高得离谱（动辄两三万美元的 H100 显卡），但如果从企业的视角来算账，它未必比订阅商业 API 更贵。更重要的是，模型本身被训练得更“会动手”——它不仅聪明，还懂得怎么用工具去做事。

这正是我觉得最打动人的地方：**未来的 AI，不只是聊天和写作，而是更像一个“能干活”的数字助手。**Moonshot 把重点放在了“如何让 AI 真正做事”这件事上，这种思路非常对味儿。

想到这里，我突然意识到：也许我们不是在看一个“又一个开源模型”，而是在见证开源和商业的赛道真正开始交汇。也许再过一两年，AI 的“主权”真的可以在我们自己手上了。那才是最让人兴奋的未来。

---

**想把你自己的视频转换为文章吗？** 尝试 **[Viddo](https://viddo.pro/)** - 这个 AI 驱动的平台可以在几分钟内将视频内容转化为引人入胜、易于阅读的文章。非常适合内容创作者、教育工作者和专业人士，他们希望将视频内容重新利用到博客、社交媒体或文档中。

[🚀 开始使用 Viddo 转换视频](https://viddo.pro/)